% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{sbfc}
\alias{sbfc}
\title{Selective Bayesian Forest Classifier algorithm}
\usage{
sbfc(TrainX = NULL, TrainY = NULL, TestX = NULL, TestY = NULL)
}
\arguments{
\item{TrainX}{matrix containing the training data}

\item{TrainY}{vector containing the class labels for the training data}

\item{TestX}{matrix containing the test data, if applicable}

\item{TestY}{vector containing the class labels for the test data}
}
\value{
An object of class \code{sbfc}:
\describe{     
\item{\code{accuracy}}{classification accuracy (on the test set if provided, otherwise cross-validation accuracy on training set)}
\item{\code{predictions}}{vector of class label predictions (for the test set if provided, otherwise for the training set)}
\item{\code{probabilities}}{matrix of class label probabilities (for the test set if provided, otherwise for the training set)}
\item{\code{runtime}}{total runtime of the algorithm in seconds}
\item{\code{parents}}{matrix representing the structures sampled by MCMC, where parents[i,j] is the index of the parent of node j at iteration i (0 if node is a root)}
\item{\code{groups}}{matrix representing the structures sampled by MCMC, where groups[i,j] indicates which group node j belongs to at iteration j (0 is noise, 1 is signal)}
\item{\code{trees}}{matrix representing the structures sampled by MCMC, where trees[i,j] indicates which tree node j belongs to at iteration j}
\item{\code{logposterior}}{vector representing the log posterior at each iteration of the MCMC}
}
}
\description{
Runs the SBFC algorithm on a discretized data set.
}
\details{
Data needs to be discretized before running SBFC.
If the test data matrix TestX is provided, SBFC runs on the entire training set TrainX, and provides predicted class labels for the test data. If the test data class vector TestY is provided, the accuracy is computed. If the test data matrix TestX is not provided, SBFC performs cross-validation on the training data set TrainX, and returns predicted classes and accuracy for the training data.  
The number of MCMC iterations is \code{max(10000, 10 * n_var)}. 
For data sets with 1000 or more variables, the output matrices are thinned by default, and contain only the thinned samples used for classification.
}
\examples{
data(chess)
chess_result = sbfc(as.matrix(chess$TrainX), as.numeric(chess$TrainY), as.matrix(chess$TestX), as.numeric(chess$TestY))
data(corral)
corral_result = sbfc(as.matrix(corral$TrainX), as.numeric(corral$TrainY)) # uses cross-validation
}

